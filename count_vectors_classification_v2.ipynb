{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model, preprocessing, model_selection,feature_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_utils.model import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 6)\n",
      "(3263, 5)\n"
     ]
    }
   ],
   "source": [
    "## using the cleaned files\n",
    "train_data = pd.read_csv(data_folder+'train_clean.csv'); print(train_data.shape)\n",
    "test_data = pd.read_csv(data_folder+'test_clean.csv'); print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>deed reason earthquake may allah forgive u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>resident asked shelter place notified officer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>people receive wildfire evacuation order cali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfire pour...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target                                         text_clean  \n",
       "0       1         deed reason earthquake may allah forgive u  \n",
       "1       1              forest fire near la ronge sask canada  \n",
       "2       1  resident asked shelter place notified officer ...  \n",
       "3       1   people receive wildfire evacuation order cali...  \n",
       "4       1  got sent photo ruby alaska smoke wildfire pour...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.@unsuckdcmetro Is the train half-derailed or half-railed? #deepthoughts'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data['target'] == 1].sample()['text'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.location.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(data_folder+'sample_submission.csv')\n",
    "# sample_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### count vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = feature_extraction.text.CountVectorizer(max_features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = count_vectorizer.fit_transform(train_data['text_clean'])\n",
    "test_vectors = count_vectorizer.transform(test_data['text_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 15670)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train_x, count_valid_x, count_train_y, count_valid_y = train_test_split(train_vectors, train_data['target'], \n",
    "                                                                              test_size = 0.15, random_state = 44)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_clf = linear_model.RidgeClassifierCV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_clf = linear_model.RidgeClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.RidgeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cross validating\n",
    "scores = model_selection.cross_val_score(clf, count_train_x, count_train_y, scoring='f1', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.70233352, 0.7090379 , 0.72380952])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.69      0.73       496\n",
      "           0       0.78      0.86      0.82       646\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      1142\n",
      "   macro avg       0.78      0.77      0.78      1142\n",
      "weighted avg       0.78      0.78      0.78      1142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(clf, count_train_x, count_train_y, count_valid_x, count_valid_y, test_vectors,\n",
    "#             submissions_data=sample_submission, submissions_file_prefix=\"ridge_submissions\"\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear_model.LogisticRegressionCV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_2 = linear_model.LogisticRegressionCV(Cs=np.arange(0.05,0.5, 0.05),\n",
    "                                          random_state=42, scoring = 'f1', class_weight='balanced', cv = 3, max_iter=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=array([0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45]),\n",
       "           class_weight='balanced', cv=3, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1.0, max_iter=300, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=42, refit=True,\n",
       "           scoring='f1', solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_2.fit(train_vectors, train_data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: array([[0.64793388, 0.65217391, 0.65332612, 0.6537007 , 0.65301724,\n",
       "         0.6483871 , 0.64775161, 0.64343164, 0.64239829],\n",
       "        [0.58854719, 0.5947068 , 0.5998978 , 0.60131379, 0.59899497,\n",
       "         0.59680639, 0.59432554, 0.59534423, 0.59545005],\n",
       "        [0.6724846 , 0.67414584, 0.67882472, 0.67806841, 0.67270896,\n",
       "         0.67566217, 0.67630923, 0.67363184, 0.67293419]])}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_2.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_2.Cs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_2.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear_model.LogisticRegression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = linear_model.LogisticRegression(C = 0.2,random_state=42, max_iter=500, class_weight = 'balanced'\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.77      0.79       496\n",
      "           0       0.83      0.86      0.84       646\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      1142\n",
      "   macro avg       0.82      0.81      0.81      1142\n",
      "weighted avg       0.82      0.82      0.82      1142\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harsha/.local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train_model(logistic_model, \n",
    "#             train_vectors, train_data['target'],train_vectors, train_data['target'],\n",
    "            count_train_x, count_train_y, count_valid_x, count_valid_y,\n",
    "#             test_vectors, submissions_data=sample_submission, submissions_file_prefix=\"clean_logistic_submissions\"  \n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(300, class_weight='balanced', oob_score=True,min_samples_split = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.69      0.75       496\n",
      "           0       0.79      0.88      0.83       646\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      1142\n",
      "   macro avg       0.80      0.78      0.79      1142\n",
      "weighted avg       0.80      0.80      0.79      1142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(rf_clf, count_train_x, count_train_y, count_valid_x, count_valid_y, \n",
    "#             test_vectors, \n",
    "#             submissions_data=sample_submission, submissions_file_prefix=\"rf_submissions\"  \n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test1 = {\n",
    "    'max_depth':range(3,10,2),\n",
    "#     'min_child_weight':range(1,6,2),\n",
    "    'learning_rate':[0.001,0.01,0.1],\n",
    "    'n_estimators':[100,250,500],\n",
    "    'gamma':[i/10.0 for i in range(0,5)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb.train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomizedSearchCV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier(njobs = -1,scale_pos_weight=4342/3271)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_rsearch = RandomizedSearchCV(xgb_clf, param_distributions=param_test1, n_iter=20, scoring=\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harsha/.local/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "          estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, njobs=-1, nthread=None, objective='binary:logistic',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1.3274228064811984, seed=None, silent=True,\n",
       "       subsample=1),\n",
       "          fit_params=None, iid='warn', n_iter=20, n_jobs=None,\n",
       "          param_distributions={'max_depth': range(3, 10, 2), 'learning_rate': [0.001, 0.01, 0.1], 'n_estimators': [100, 250, 500], 'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_rsearch.fit(X=count_train_x,y=count_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = xgb_rsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.1, 'gamma': 0.1}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(n_estimators=500, max_depth=9, learning_rate=0.1, gamma=0.1, njobs = -1, scale_pos_weight=4342/3271)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.74      0.77       496\n",
      "           0       0.81      0.87      0.84       646\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      1142\n",
      "   macro avg       0.81      0.80      0.81      1142\n",
      "weighted avg       0.81      0.81      0.81      1142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(xgb_model, \n",
    "#             train_vectors, train_data['target'],train_vectors, train_data['target'],\n",
    "            count_train_x, count_train_y, count_valid_x, count_valid_y,\n",
    "#             test_vectors, submissions_data=sample_submission, submissions_file_prefix=\"clean_xgb_submissions\"  \n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, optimizers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_bias: [-0.28660041]\n"
     ]
    }
   ],
   "source": [
    "neg = count_train_y.value_counts()[0]\n",
    "pos = count_train_y.value_counts()[1]\n",
    "initial_bias = np.log([pos/neg])\n",
    "print(\"initial_bias: {}\".format(initial_bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizers.Adam?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers.Dense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nn(input_size, output_bias = None):\n",
    "    if output_bias is not None:\n",
    "        output_bias = keras.initializers.Constant(output_bias)\n",
    "    \n",
    "    input_layer = layers.Input((input_size,))\n",
    "    hidden_layer = layers.Dense(512, activation = 'sigmoid')(input_layer)\n",
    "    hidden_layer = layers.Dropout(0.35)(hidden_layer)\n",
    "    hidden_layer = layers.Dense(256, activation = 'sigmoid')(hidden_layer)\n",
    "    hidden_layer = layers.Dropout(0.35)(hidden_layer)\n",
    "    hidden_layer = layers.Dense(128, activation = 'sigmoid')(hidden_layer)\n",
    "    hidden_layer = layers.Dropout(0.35)(hidden_layer)\n",
    "    hidden_layer = layers.Dense(64, activation = 'sigmoid')(hidden_layer)\n",
    "    hidden_layer = layers.Dropout(0.35)(hidden_layer)\n",
    "    hidden_layer = layers.Dense(32, activation = 'sigmoid')(hidden_layer)\n",
    "    hidden_layer = layers.Dropout(0.35)(hidden_layer)\n",
    "    hidden_layer = layers.Dense(16, activation = 'sigmoid')(hidden_layer)\n",
    "#     hidden_layer = layers.Dropout(0.25)(hidden_layer)\n",
    "    output_layer = layers.Dense(1, activation = 'sigmoid',bias_initializer=output_bias )(hidden_layer)\n",
    "    \n",
    "    classifier = models.Model(inputs = input_layer, outputs = output_layer)\n",
    "    classifier.compile(optimizer=optimizers.Adam(0.0005), loss = 'binary_crossentropy')\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = create_nn(train_vectors.shape[1], output_bias=initial_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        [(None, 15670)]           0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 512)               8023552   \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 8,198,657\n",
      "Trainable params: 8,198,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "203/203 [==============================] - 8s 34ms/step - loss: 0.6838 - val_loss: 0.6845\n",
      "Epoch 2/50\n",
      "203/203 [==============================] - 8s 40ms/step - loss: 0.6833 - val_loss: 0.6847\n",
      "Epoch 3/50\n",
      "203/203 [==============================] - 6s 32ms/step - loss: 0.6857 - val_loss: 0.6842\n",
      "Epoch 4/50\n",
      "203/203 [==============================] - 8s 37ms/step - loss: 0.6822 - val_loss: 0.6670\n",
      "Epoch 5/50\n",
      "203/203 [==============================] - 8s 37ms/step - loss: 0.6121 - val_loss: 0.4603\n",
      "Epoch 6/50\n",
      "203/203 [==============================] - 8s 37ms/step - loss: 0.4325 - val_loss: 0.4482\n",
      "Epoch 7/50\n",
      "203/203 [==============================] - 8s 38ms/step - loss: 0.3527 - val_loss: 0.4592\n",
      "Epoch 8/50\n",
      "203/203 [==============================] - 8s 38ms/step - loss: 0.3020 - val_loss: 0.4736\n",
      "Epoch 9/50\n",
      "203/203 [==============================] - 8s 39ms/step - loss: 0.2733 - val_loss: 0.4759\n",
      "Epoch 10/50\n",
      "203/203 [==============================] - 8s 40ms/step - loss: 0.2546 - val_loss: 0.5133\n",
      "Epoch 11/50\n",
      "203/203 [==============================] - 8s 38ms/step - loss: 0.2248 - val_loss: 0.5199\n",
      "Classification report : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.76      0.77       496\n",
      "           0       0.82      0.84      0.83       646\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      1142\n",
      "   macro avg       0.80      0.80      0.80      1142\n",
      "weighted avg       0.80      0.80      0.80      1142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(classifier,\n",
    "#             train_vectors.toarray(), train_data['target'],train_vectors.toarray(), train_data['target'],\n",
    "            count_train_x.toarray(), count_train_y, count_valid_x.toarray(), count_valid_y,\n",
    "            test_vectors = test_vectors, neural_network = True, epochs = 50,\n",
    "#                 submissions_data = sample_submission, submissions_file_prefix=\"clean_nn_submissions\" \n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "callback = EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "203/203 [==============================] - 2s 7ms/step - loss: 0.7050 - val_loss: 0.6859\n",
      "Epoch 2/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.6986 - val_loss: 0.6729\n",
      "Epoch 3/50\n",
      "203/203 [==============================] - 1s 4ms/step - loss: 0.6826 - val_loss: 0.6517\n",
      "Epoch 4/50\n",
      "203/203 [==============================] - 1s 4ms/step - loss: 0.6496 - val_loss: 0.6236\n",
      "Epoch 5/50\n",
      "203/203 [==============================] - 1s 4ms/step - loss: 0.6135 - val_loss: 0.5912\n",
      "Epoch 6/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.5702 - val_loss: 0.5584\n",
      "Epoch 7/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.5245 - val_loss: 0.5290\n",
      "Epoch 8/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.4897 - val_loss: 0.5038\n",
      "Epoch 9/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.4456 - val_loss: 0.4835\n",
      "Epoch 10/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.4131 - val_loss: 0.4673\n",
      "Epoch 11/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.3785 - val_loss: 0.4549\n",
      "Epoch 12/50\n",
      "203/203 [==============================] - 1s 4ms/step - loss: 0.3470 - val_loss: 0.4452\n",
      "Epoch 13/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.3370 - val_loss: 0.4377\n",
      "Epoch 14/50\n",
      "203/203 [==============================] - 1s 4ms/step - loss: 0.3215 - val_loss: 0.4323\n",
      "Epoch 15/50\n",
      "203/203 [==============================] - 1s 4ms/step - loss: 0.3036 - val_loss: 0.4286\n",
      "Epoch 16/50\n",
      "203/203 [==============================] - 1s 4ms/step - loss: 0.2752 - val_loss: 0.4267\n",
      "Epoch 17/50\n",
      "203/203 [==============================] - 1s 4ms/step - loss: 0.2537 - val_loss: 0.4250\n",
      "Epoch 18/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.2433 - val_loss: 0.4248\n",
      "Epoch 19/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.2329 - val_loss: 0.4255\n",
      "Epoch 20/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.2181 - val_loss: 0.4267\n",
      "Epoch 21/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.2133 - val_loss: 0.4292\n",
      "Epoch 22/50\n",
      "203/203 [==============================] - 1s 4ms/step - loss: 0.2034 - val_loss: 0.4319\n",
      "Epoch 23/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.1901 - val_loss: 0.4351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcb05362510>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(count_train_x.toarray(), count_train_y,epochs=50, validation_data=(count_valid_x.toarray(), count_valid_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04936668],\n",
       "       [0.956838  ],\n",
       "       [0.03449565],\n",
       "       ...,\n",
       "       [0.04843271],\n",
       "       [0.05063567],\n",
       "       [0.98669565]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(count_valid_x.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(count_valid_x.toarray()).argmax(axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "526"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(classifier.predict(count_valid_x.toarray())>0.2,1,0).sum()#.argmax(axis=-1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier.predict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
